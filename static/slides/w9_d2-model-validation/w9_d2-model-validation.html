<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Model validation   ✅</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Çetinkaya-Rundel" />
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link href="libs/countdown/countdown.css" rel="stylesheet" />
    <script src="libs/countdown/countdown.js"></script>
    <link rel="stylesheet" href="../slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Model validation <br> ✅
### Dr. Çetinkaya-Rundel

---





layout: true
  
&lt;div class="my-footer"&gt;
&lt;span&gt;
Dr. Mine Çetinkaya-Rundel -
&lt;a href="https://introds.org" target="_blank"&gt;introds.org
&lt;/a&gt;
&lt;/span&gt;
&lt;/div&gt; 

---






## Announcements

- ...

---

class: center, middle

# Model validation

---

## Overfitting

- The data we are using to construct our models come from a larger population.
- Ultimately we want our model to tell us how the population works, not just the sample we have.
- If the model we fit is too tailored to our sample, it might not perform as well with the remaining population. This means the model is "overfitting" our data.
- We measure this using **model validation** techniques.
- Note: Overfitting is not a huge concern with linear models with low level 
interactions, however it can be with more complex and flexible models. The 
following is just an example of model validation, even though we're using it 
in a scenario where the concern for overfitting is not high.

---

## Model validation

- One commonly used model validation technique is to partition your data 
into training and testing set
- That is, fit the model on the training data
- And test it on the testing data
- Evaluate model performance using `\(RMSE\)`, root-mean squared error

$$ RMSE = \sqrt{\frac{\sum_{i = 1}^n (y_i - \hat{y}_i)^2}{n}} $$

.question[
Do you think we should prefer low or high RMSE?
]

---

## Random sampling and reproducibility

Gotta set a seed!


```r
set.seed(3518)
```

- We will be taking random samples, but we want the analysis to be 
reproducible (across different people running the sama analysis as well as 
for the same person running the analysis at different times)
- So we need to tell R where to start the (pseudo) random number generation



---

## Cross validation

More specifically, **k-fold cross validation**:

- Split your data into k folds
- Use 1 fold for testing and the remaining (k - 1) folds for training
- Repeat k times

---

## Aside -- the modulo operator


```r
9 %% 5
```

```
## [1] 4
```

--

.pull-left[

```
## # A tibble: 8 x 2
##     obs  fold
##   &lt;int&gt; &lt;int&gt;
## 1     1     1
## 2     2     2
## 3     3     3
## 4     4     4
## 5     5     5
## 6     6     1
## 7     7     2
## 8     8     3
```
]

--

.pull-right[
.midi[

```r
(1:8) %% 5
```

```
## [1] 1 2 3 4 0 1 2 3
```

```r
((1:8) - 1) %% 5
```

```
## [1] 0 1 2 3 4 0 1 2
```

```r
(((1:8) - 1) %% 5) + 1
```

```
## [1] 1 2 3 4 5 1 2 3
```
]
]

---

## Prepping your data for 5-fold CV


```r
evals_cv &lt;- evals %&gt;%
  sample_n(nrow(evals)) %&gt;%               # scramble rows
  rowid_to_column() %&gt;%                   # add id column
  mutate( fold = ((rowid - 1) %% 5) + 1 ) # add fold column

evals_cv %&gt;% 
  count(fold)
```

```
## # A tibble: 5 x 2
##    fold     n
##   &lt;dbl&gt; &lt;int&gt;
## 1     1    93
## 2     2    93
## 3     3    93
## 4     4    92
## 5     5    92
```

---

## CV 1


```r
test_fold &lt;- 1
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
(rmse_test1 &lt;- rmse(mod, test))
```

```
## [1] 0.5145405
```

---

## RMSE on training vs. testing

.question[
Would you expect the RMSE to be higher for your training data or your testing data? Why?
]

---

## RMSE on training vs. testing

RMSE for testing:
.small[

```r
(rmse_test1 &lt;- rmse(mod, test))
```

```
## [1] 0.5145405
```
]

RMSE for training:
.small[

```r
(rmse_train1 &lt;- rmse(mod, train))
```

```
## [1] 0.4955728
```
]

---

## CV 2


```r
test_fold &lt;- 2
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
```


```r
(rmse_test2 &lt;- rmse(mod, test))
```

```
## [1] 0.5436487
```

```r
(rmse_train2 &lt;- rmse(mod, train))
```

```
## [1] 0.488579
```

---

## CV 3


```r
test_fold &lt;- 3
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
```


```r
(rmse_test3 &lt;- rmse(mod, test))
```

```
## [1] 0.4950412
```

```r
(rmse_train3 &lt;- rmse(mod, train))
```

```
## [1] 0.5016374
```

---

## CV 4


```r
test_fold &lt;- 4
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
```


```r
(rmse_test4 &lt;- rmse(mod, test))
```

```
## [1] 0.5164744
```

```r
(rmse_train4 &lt;- rmse(mod, train))
```

```
## [1] 0.4956887
```

---

## CV 5


```r
test_fold &lt;- 5
test &lt;- evals_cv %&gt;% filter(fold == test_fold)
train &lt;- evals_cv %&gt;% filter(fold != test_fold)
mod &lt;- lm(score ~ ethnicity + gender + language + age + cls_perc_eval + 
    cls_credits + bty_avg, data = train)
```


```r
(rmse_test5 &lt;- rmse(mod, test))
```

```
## [1] 0.47848
```

```r
(rmse_train5 &lt;- rmse(mod, train))
```

```
## [1] 0.5052493
```

---

## Putting it altogether

&lt;img src="w9_d2-model-validation_files/figure-html/unnamed-chunk-19-1.png" width="1500" /&gt;

---

## How does RMSE compare to y?

- `score` summary stats:


```
## # A tibble: 1 x 6
##     min   max  mean   med    sd   IQR
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1   2.3     5  4.17   4.3 0.544 0.800
```

- `rmse_test` summary stats:


```
## # A tibble: 1 x 6
##     min   max  mean   med     sd    IQR
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 0.478 0.544 0.510 0.515 0.0246 0.0214
```

---

class: center, middle

# Prediction

---

## New observation

To make a prediction for a new observation we need to create a data frame with that observation.

.question[
Suppose we want to make a prediction for a 37 year old white woman professor who received her education at an English speaking country and who teaches a multi credit course. 80% of her classes tend to fill out evaluations, and she's average looiking (beauty score = 2.5).

The following won't work. Why? How would you correct it?
]


```r
new_prof &lt;- data_frame(ethnicity = "white",
                       sex = "woman",
                       language = "English",
                       age = 35, 
                       cls_perc_eval = 0.80,
                       cls_credits = "multi-credit",
                       bty_avg = 2.5)
```

---

## New observation, corrected


```r
new_prof &lt;- data_frame(ethnicity = "not minority",
                       gender = "female",
                       language = "english",
                       age = 35, 
                       cls_perc_eval = 0.80,
                       cls_credits = "multi credit",
                       bty_avg = 2.5)
```

---

## Prediction


```r
predict(selected_model, newdata = new_prof)
```

```
##        1 
## 3.642981
```

---

## Uncertainty around prediction

Prediction interval around `\(\hat{y}\)` for new data (score for a prof with given characteristics):


```r
predict(selected_model, newdata = new_prof, interval = "prediction")
```

```
##        fit      lwr      upr
## 1 3.642981 2.626502 4.659461
```

---

class: center, middle

# Logistic regression

---


```r
email &lt;- email %&gt;%
  mutate(
    spam = if_else(spam == 0, "No", "Yes"),
    urgent_subj = if_else(urgent_subj == 0, "No", "Yes")
    )
```


# Spam filters

We will examine a data set of emails where we are interested in identifying 
spam messages. 

- Data from 3921 emails and 21 variables on them.
- The outcome is whether the email is spam or not.
- Explanatory variables are number of characters, whether the word inherit 
was in the email, number of times the word inherit shows up in the email, etc.

---

# Spam vs. number of characters and urgent subject

.pull-left[
&lt;img src="w9_d2-model-validation_files/figure-html/unnamed-chunk-27-1.png" width="1500" /&gt;
]
.pull-right[
&lt;img src="w9_d2-model-validation_files/figure-html/unnamed-chunk-28-1.png" width="1500" /&gt;
]
---

# Modeling spam

It seems clear that both number of characters and urgent message are related 
to whether the email is spam. How do we come up with a model that will let us 
explore this relationship?

---

# Modeling spam

Even if we set not spam to 0 and spam to 1, this isn’t something we can 
reasonably fit a linear model to - we need something more.

&lt;img src="w9_d2-model-validation_files/figure-html/unnamed-chunk-29-1.png" width="1500" /&gt;

---

Another way to think about the problem:

- We can treat each outcome (spam and not) as successes and failures arising 
from separate Bernoulli trials

- Each Bernoulli trial can have a separate probability of success

$$ y_i ∼ Bern(p) $$
- We can then use the predictor variables to model that probability of success, `\(p_i\)`

- We can’t just use a linear model for `\(p_i\)` (since `\(p_i\)` must be between 0 and 
1) but we can transform the linear model to have the appropriate range

---

## Generalized linear models

- It turns out that this is a very general way of addressing many
problem in regression, and the resulting models are called
generalized linear models (GLMs)

--
- Logistic regression is just one example.

---
- All generalized linear models have the following three characteristics:
  -  A probability distribution describing a generative model for the 
  outcome variable
  - A linear model:
  $$ \eta = \beta_0 + \beta_1 X_1 + \cdots + \beta_k X_k $$
  - A link function that relates the linear model to the parameter of the 
  outcome distribution
  
---

## Logistic regression

Logistic regression is a GLM used to model a binary categorical outcome using numerical and categorical predictors.

--
To finish specifying the Logistic model we just need to define a reasonable link function that connects `\(\eta_i\)` to `\(p_i\)`. There are a variety of options but the most commonly used is the logit function.

Logit function:

`$$logit(p) = \log\left(\frac{p}{1-p}\right),\text{ for `\(0\le p \le 1\)`}$$`

---


```r
d &lt;- tibble(p = seq(0.001, 0.999, len = 1000)) %&gt;%
  mutate(logit_p = log(p/(1-p)))

ggplot(d, aes(x=p,y=logit_p)) + 
  geom_line() + 
  xlim(0,1) + 
  ylab("logit(p)") +
  theme_minimal()
```

&lt;img src="w9_d2-model-validation_files/figure-html/unnamed-chunk-30-1.png" width="1500" /&gt;

---


```r
d &lt;- tibble(x = seq(-5, 5, len = 1000)) %&gt;%
  mutate(inv_logit_x = exp(x)/(1+exp(x)))

ggplot(d, aes(x=x,y=inv_logit_x)) + 
  geom_line() + 
  xlim(-5,5) + 
  ylab("p = inv_logit(x)") +
  theme_minimal()
```

&lt;img src="w9_d2-model-validation_files/figure-html/unnamed-chunk-31-1.png" width="1500" /&gt;

---

## Properties of the logit

- The logit function takes a value between 0 and 1 and maps it to a value between `\(-\infty\)` and `\(\infty\)`.

--
- Inverse logit (logistic) function:
`$$g^{-1}(x) = \frac{\exp(x)}{1+\exp(x)} = \frac{1}{1+\exp(-x)}$$`

--
- The inverse logit function takes a value between `\(-\infty\)` and `\(\infty\)` and maps it to a value between 0 and 1.

--
- This formulation is also useful for interpreting the model, since the logit can be interpreted as the log odds of a success - more on this later.

---

## The logistic regression model

- The three GLM criteria give us:
  - `\(y_i \sim \text{Bern}(p_i)\)`
  - `\(\eta_i = \beta_0+\beta_1 x_{1,i} + \cdots + \beta_n x_{n,i}\)`
  - `\(\text{logit}(p_i) = \eta_i\)`

--
- From which we get,

`$$p_i = \frac{\exp(\beta_0+\beta_1 x_{1,i} + \cdots + \beta_k x_{k,i})}{1+\exp(\beta_0+\beta_1 x_{1,i} + \cdots + \beta_k x_{k,i})}$$`
---

## Modeling spam

- In R we fit a GLM in the same way as a linear model except we
use `glm()` instead of `lm()`. 

--
- We specify the type of GLM to fit using the `family` argument.


```r
spam_model &lt;- glm(spam ~ num_char, data = email, family = "binomial")
tidy(spam_model)
```

```
## # A tibble: 2 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)  -1.80     0.0716     -25.1  2.04e-139
## 2 num_char     -0.0621   0.00801     -7.75 9.50e- 15
```

---

## Spam model


```r
tidy(spam_model)
```

```
## # A tibble: 2 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept)  -1.80     0.0716     -25.1  2.04e-139
## 2 num_char     -0.0621   0.00801     -7.75 9.50e- 15
```

--

Model:
`$$\log\left(\frac{p}{1-p}\right) = -1.80-0.0621\times \text{num_char}$$`

---

## P(spam) for an email with 2000 characters 

`$$\log\left(\frac{p}{1-p}\right) = -1.80-0.0621\times 2$$`
--
`$$\frac{p}{1-p} = \exp(-1.9242) = 0.15$$`
--
`$$p = 0.15 \times (1 - p)$$`
--
`$$p = 0.15 - 0.15p \rightarrow 1.15p = 0.15$$`
--
`$$p = 0.15 / 1.15 = 0.13$$`

---

.question[
What is the probability that an email with 5000 characters is spam? What about 
an email with 10000 characters?
]

<div class="countdown" id="timer_5dcbdf20" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">05</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightLines": true,
"highlightStyle": "solarized-light",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
